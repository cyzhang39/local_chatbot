from langchain_community.llms import ChatGLM
# from core.config import settings


llm = ChatGLM(endpoint_url="http://127.0.0.1:8000")
answer = llm.invoke("ä½ å¥½")
print(answer)

'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'